Сравнение разных способов хранения данных:

|         | size   | latency (DC / cross DC) | throughput |
| ------- | ------ | ----------------------- | ---------- |
| Network | ---    | 1 ms / 10 ms            | 1 Gb / s   |
| RAM     | 1 Tb   | 100 ns                  | 10 Gb / s  |
| HDD     | 100 Tb | 10 ms                   | 1 Gb / s   |
| SSD     | 100 Tb | 100 micro s             | 10 Gb / s  |
## SSD
Память в SSD разбита на блоки, в каждом блоке 512 страниц по 4кб. Плюс в том, что в разных блоках мы можем работать парралельно. Страницы состоят из ячеек (cell), в каждую ячеку записывается единица информации. SSD можно сломать постоянной перезаписью в одну ячейку.
>[!attention]
>нет перезаписи, при перезаписи данные пишутся в новое место в памяти.

WA - write amplication - то во сколько раз физически мы больше пишем в памяти, чем логически. 
RA - reade amplification - то во сколько раз физически мы больше читаем, чем логически.
SA - space amplification - то во сколько раз физически мы больше занимаем места, чем логически.

Как вычислять битые данные:
1) Checksum
2) Write ahead logs

# External memory model
$t_{phys}(x) = 10 ms + \frac{x}{1 Gb / s}$

$t_{model}(x) = \# \text{I/O operations} = \frac{x}{B}$. B подбирается так, чтобы $t_{phys} \approx t_{model}$.

Scan(N) - прочитать N байт. Сложность этой операции O(N / B).

Merge(N) = O(N / B). (Сливаем k отсортированных массивов в один, всего N данных.
Каждый блок будет один раз считан, один раз записан, поэтому 2 N / B = O(N /
B)). 

- Вообще, в асимптотике *времени* должен присутствовать логарифм, так как для
  мёрджа k массивов нужна куча, однако поддерживать кучу намного дешевле, чем
  писать и читать из памяти, поэтому опустим его. Наша асимптотика data
  intensive, считаем только I/O операции.

Join(N) = Sort(N) + Scan(N). Сортируем мёрдж сортом, сливаем блоки размером M
(размер RAM). Sort(N) = $O(\frac{N}{B} \cdot \log_{\frac{M}{B}}{\frac{N}{M}})$.
Оптимизация использовать два разных альфа()
## Оптимизации
write bufferization
read ahead

## B-tree
B - размер блока
Для всех вершин кроме root степень: a <= deg <= b
Для  root степень: 2 <= deg <= b

Insert
Split вершины если превисилы степень b
Delete
Если в вершине стало мень a, то мы берем из соседней a штук и объеденяем. Thrashhold такого объединения 3a.

# Buffered tree
n - количество ключей
buffer <= m (где m - размер оперативки)
количество листьев m / n
![](https://i.imgur.com/cZuDTQT.png)

height = log_{m / b}(n / b)
\[ log_{m/b}(n/b) = \frac{log(n/b)}{log(m/b)} \] 

Single flush
Когда 
![](https://i.imgur.com/h0YiwwA.png)
![](https://i.imgur.com/UIF6j05.png)

remove - порождение элемента с tombstone.

ключей может быть несколько, поэтому можем хранить время.
![](https://i.imgur.com/QTR0H1z.png)


# Heap
![](https://i.imgur.com/Zwvx6RT.png)
Храним в RAM top ключей в виде отсортированного массива или кучи. На диске храним просто буфферезированное дерево.
Если добавили достаточно большой элемент, то вставляем в в top (RAM)
Если добавили маленький или нужно переложить маленький ключ из RAM на диск, то кладем его в буфер в RAM.

Когда заканчивается top, то мы делаем flush буффера, который в RAM в buffered tree.
Когда переполняется буффер на RAM делаем то же самое.
![](https://i.imgur.com/mpMKOWc.png)
![](https://i.imgur.com/igLzypi.png)

# B-eps дерево
Разобьем буффер B дерева на две состовляющие pivot и buffer:
![](https://i.imgur.com/NcSz1db.png)

![](https://i.imgur.com/35hwnof.png)

Сравнение:
![](https://i.imgur.com/qnnffKi.png)
